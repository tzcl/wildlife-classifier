{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b739c0e2",
   "metadata": {},
   "source": [
    "# Image Detection Demo with PytorchWildlife\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1197e180",
   "metadata": {},
   "source": [
    "This tutorial guides you on how to use PyTorchWildlife to separate positive and negative animal detections. We will go through the process of setting up the environment, defining the detection model, as well as performing inference and saving the results in different ways.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Install PytorchWildlife running the following commands:\n",
    "\n",
    "```bash\n",
    "conda create -n pytorch_wildlife python=3.8 -y\n",
    "conda activate pytorch_wildlife\n",
    "pip install PytorchWildlife\n",
    "```\n",
    "\n",
    "Also, make sure you have a CUDA-capable GPU if you intend to run the model on a GPU. This notebook can also run on CPU.\n",
    "\n",
    "## Importing libraries\n",
    "\n",
    "First, we'll start by importing the necessary libraries and modules.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c44e7713",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Ultralytics Settings v0.0.6 file âœ… \n",
      "View Ultralytics Settings with 'yolo settings' or at '/Users/tobylaw/Library/Application Support/Ultralytics/settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from PytorchWildlife.models import detection as pw_detection\n",
    "from PytorchWildlife import utils as pw_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abd07b5",
   "metadata": {},
   "source": [
    "## Model Initialization\n",
    "\n",
    "We will initialize the MegaDetectorV5 model for image detection. This model is designed for detecting animals in images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb25db43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.55 ðŸš€ Python-3.9.6 torch-2.5.1 CPU (Apple M1)\n",
      "YOLOv9c summary (fused): 384 layers, 25,321,561 parameters, 0 gradients, 102.3 GFLOPs\n"
     ]
    }
   ],
   "source": [
    "# Setting the device to use for computations ('cuda' indicates GPU)\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "if DEVICE == \"cuda\":\n",
    "    torch.cuda.set_device(0)\n",
    "\n",
    "# Initializing the MegaDetectorV6 model for image detection\n",
    "detection_model = pw_detection.MegaDetectorV6(\n",
    "    device=DEVICE, pretrained=True, version=\"yolov9c\"\n",
    ")\n",
    "\n",
    "# Uncomment the following line to use MegaDetectorV5 instead of MegaDetectorV6\n",
    "# detection_model = pw_detection.MegaDetectorV5(device=DEVICE, pretrained=True, version=\"a\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3cfe3fd",
   "metadata": {},
   "source": [
    "## Variable definition\n",
    "\n",
    "In order to process the batch detection, we will define an input directory where the images are stored, a confidence threshold and an output directory to copy the positive and negative images into distinctive folders. If you want to follow this tutorial with your own data, modify the following variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "735a3f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tgt_folder_path = \"/Users/tobylaw/Documents/cape-liptrap\"\n",
    "tgt_folder_path = \"./imgs\"\n",
    "output_path = \"output\"\n",
    "classified_path = \"classified\"\n",
    "threshold = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e23329c",
   "metadata": {},
   "source": [
    "## Batch Image Detection\n",
    "\n",
    "Next, we'll demonstrate how to process multiple images in batches. This is useful when you have a large number of images and want to process them efficiently.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "561eff0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 animal, 417.0ms\n",
      "1: 480x640 1 animal, 417.0ms\n",
      "2: 480x640 (no detections), 417.0ms\n",
      "3: 480x640 (no detections), 417.0ms\n",
      "4: 480x640 (no detections), 417.0ms\n",
      "5: 480x640 1 animal, 417.0ms\n",
      "6: 480x640 (no detections), 417.0ms\n",
      "7: 480x640 1 animal, 417.0ms\n",
      "8: 480x640 1 animal, 417.0ms\n",
      "Speed: 4.2ms preprocess, 417.0ms inference, 2.6ms postprocess per image at shape (9, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:05<00:00,  5.21s/it]\n"
     ]
    }
   ],
   "source": [
    "results = detection_model.batch_image_detection(tgt_folder_path, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb41830b",
   "metadata": {},
   "source": [
    "## Separate positive and negative detections\n",
    "\n",
    "PytorchWildlife allows to copy the files from your original folder to a new directory containing the \"Animal\" and \"No-animal\" subdirectories. A detection is considered positive if the prediction confidence is higher than the threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63310ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9 files were successfully separated'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.makedirs(output_path, exist_ok=True)\n",
    "os.makedirs(classified_path, exist_ok=True)\n",
    "json_file = os.path.join(output_path, \"detection_results.json\")\n",
    "pw_utils.save_detection_json(\n",
    "    results,\n",
    "    json_file,\n",
    "    categories=detection_model.CLASS_NAMES,\n",
    "    exclude_category_ids=[],  # Category IDs can be found in the definition of each model.\n",
    "    exclude_file_path=tgt_folder_path,\n",
    ")\n",
    "\n",
    "pw_utils.save_detection_images(results, output_path)\n",
    "\n",
    "# Separate the positive and negative detections through file copying:\n",
    "pw_utils.detection_folder_separation(json_file, output_path, classified_path, threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ee1d7b",
   "metadata": {},
   "source": [
    "### Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "\n",
    "### Licensed under the MIT License.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
